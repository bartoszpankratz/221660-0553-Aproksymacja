{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zasady budowania modeli deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dlaczego Julia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W trakcie kursu pracować będziemy w języku [Julia](https://julialang.org/). Dlaczego?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Język skryptowy (jak Python  czy R)\n",
    "- Szybkość  (jak C)\n",
    "- Silny  system [typów](https://upload.wikimedia.org/wikipedia/commons/d/d9/Julia-number-type-hierarchy.svg) \n",
    "- Wbudowane  zrównoleglanie  obliczeń\n",
    "- Łatwość  integracji  integracji (Python, R, C, …) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literatura "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przydatne linki:\n",
    "- [Kursy Julia Academy](https://juliaacademy.com/)\n",
    "- [Podręcznik Boyda i Vandenberghe](http://vmls-book.stanford.edu/)\n",
    "- [Julia Express](https://github.com/bkamins/The-Julia-Express)\n",
    "- [wykłady Quantitative Economics Sargenta i Stachurskiego](https://lectures.quantecon.org/jl/)\n",
    "- [Julia dla Data Science](http://ucidatascienceinitiative.github.io/IntroToJulia/)\n",
    "- [Think Julia](https://benlauwens.github.io/ThinkJulia.jl/latest/book.html)\n",
    "- [materiały dostępne na stronie języka](https://julialang.org/learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. DataFrames.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteka [<tt>DataFrames</tt>](https://juliadata.github.io/DataFrames.jl/stable/man/getting_started.html) jest narzędziem pozwalającym na efektywną i wygodną pracę ze zbiorami danych. Jest implementacja znanych z <tt>R</tt> ramek danych, oferując wszystkie znane z <tt>R</tt> narzędzia, zaimplementowane w wyraźnie efektywniejszy obliczeniowo sposób. Warto zapoznać się ze szczegółowym [wprowadzeniem do <tt>DataFrames</tt> ](https://github.com/bkamins/Julia-DataFrames-Tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Plots.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Plots]() to podstawowa bibliotka do tworzenia wykresów w Julii. Jedną z jej głównych zalet jest to, że pozwala na wykorzystanie wielu [backendów](http://docs.juliaplots.org/latest/backends/). Warto zapoznać się z [dokumenacją](http://docs.juliaplots.org/latest/) tej biblioteki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przykład motywacyjny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od prostego przykładu. Dla australijskich danych dotyczących wniosków o karty kredytowe (dostepnych [tutaj](http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/australian/australian.dat)) zbudujmy model orkreślający prawdopodobieństwo decyzji o odmowie wydania karty kredytowej. Zacznijmy od odpowiedniedgo przygotowania danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "using PyPlot\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isfile(\"australian.dat\") ||\n",
    " download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/\n",
    "    statlog/australian/australian.dat\")\n",
    "rawdata = readdlm(\"australian.dat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th><th>x5</th><th>x6</th><th>x7</th><th>x8</th><th>x9</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 15 columns (omitted printing of 6 columns)</p><tr><th>1</th><td>1.0</td><td>22.08</td><td>11.46</td><td>0.0</td><td>4.0</td><td>4.0</td><td>1.585</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>22.67</td><td>7.0</td><td>0.0</td><td>8.0</td><td>4.0</td><td>0.165</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>29.58</td><td>1.75</td><td>1.0</td><td>4.0</td><td>4.0</td><td>1.25</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>0.0</td><td>21.67</td><td>11.5</td><td>1.0</td><td>5.0</td><td>3.0</td><td>0.0</td><td>1.0</td><td>1.0</td></tr><tr><th>5</th><td>1.0</td><td>20.17</td><td>8.17</td><td>0.0</td><td>6.0</td><td>4.0</td><td>1.96</td><td>1.0</td><td>1.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& x1 & x2 & x3 & x4 & x5 & x6 & x7 & x8 & x9 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 22.08 & 11.46 & 0.0 & 4.0 & 4.0 & 1.585 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 22.67 & 7.0 & 0.0 & 8.0 & 4.0 & 0.165 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 29.58 & 1.75 & 1.0 & 4.0 & 4.0 & 1.25 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 0.0 & 21.67 & 11.5 & 1.0 & 5.0 & 3.0 & 0.0 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\t5 & 1.0 & 20.17 & 8.17 & 0.0 & 6.0 & 4.0 & 1.96 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×15 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m x1      \u001b[0m\u001b[1m x2      \u001b[0m\u001b[1m x3      \u001b[0m\u001b[1m x4      \u001b[0m\u001b[1m x5      \u001b[0m\u001b[1m x6      \u001b[0m\u001b[1m x7      \u001b[0m\u001b[1m x8      \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     1.0    22.08    11.46      0.0      4.0      4.0    1.585      0.0  ⋯\n",
       "   2 │     0.0    22.67     7.0       0.0      8.0      4.0    0.165      0.0\n",
       "   3 │     0.0    29.58     1.75      1.0      4.0      4.0    1.25       0.0\n",
       "   4 │     0.0    21.67    11.5       1.0      5.0      3.0    0.0        1.0\n",
       "   5 │     1.0    20.17     8.17      0.0      6.0      4.0    1.96       1.0  ⋯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrames.DataFrame(rawdata)\n",
    "rename!(df,:x15 => :class)\n",
    "df[!,:x4] = [x == 1 ? 1.0 : 0.0 for x in df[!,:x4]]\n",
    "df[!,:x12] = [x == 1 ? 1.0 : 0.0 for x in df[!,:x12]]\n",
    "df[!,:x14] = log.(df[!,:x14])\n",
    "first(df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int64</th><th>DataType</th></tr></thead><tbody><p>15 rows × 7 columns</p><tr><th>1</th><td>x1</td><td>0.678261</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>2</th><td>x2</td><td>31.5682</td><td>13.75</td><td>28.625</td><td>80.25</td><td>0</td><td>Float64</td></tr><tr><th>3</th><td>x3</td><td>4.75872</td><td>0.0</td><td>2.75</td><td>28.0</td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>x4</td><td>0.236232</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>5</th><td>x5</td><td>7.37246</td><td>1.0</td><td>8.0</td><td>14.0</td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>x6</td><td>4.69275</td><td>1.0</td><td>4.0</td><td>9.0</td><td>0</td><td>Float64</td></tr><tr><th>7</th><td>x7</td><td>2.22341</td><td>0.0</td><td>1.0</td><td>28.5</td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>x8</td><td>0.523188</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>9</th><td>x9</td><td>0.427536</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>10</th><td>x10</td><td>2.4</td><td>0.0</td><td>0.0</td><td>67.0</td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>x11</td><td>0.457971</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>12</th><td>x12</td><td>0.0826087</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>13</th><td>x13</td><td>184.014</td><td>0.0</td><td>160.0</td><td>2000.0</td><td>0</td><td>Float64</td></tr><tr><th>14</th><td>x14</td><td>2.97232</td><td>0.0</td><td>1.79176</td><td>11.5129</td><td>0</td><td>Float64</td></tr><tr><th>15</th><td>class</td><td>0.444928</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Float64 & Float64 & Float64 & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & x1 & 0.678261 & 0.0 & 1.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t2 & x2 & 31.5682 & 13.75 & 28.625 & 80.25 & 0 & Float64 \\\\\n",
       "\t3 & x3 & 4.75872 & 0.0 & 2.75 & 28.0 & 0 & Float64 \\\\\n",
       "\t4 & x4 & 0.236232 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t5 & x5 & 7.37246 & 1.0 & 8.0 & 14.0 & 0 & Float64 \\\\\n",
       "\t6 & x6 & 4.69275 & 1.0 & 4.0 & 9.0 & 0 & Float64 \\\\\n",
       "\t7 & x7 & 2.22341 & 0.0 & 1.0 & 28.5 & 0 & Float64 \\\\\n",
       "\t8 & x8 & 0.523188 & 0.0 & 1.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t9 & x9 & 0.427536 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t10 & x10 & 2.4 & 0.0 & 0.0 & 67.0 & 0 & Float64 \\\\\n",
       "\t11 & x11 & 0.457971 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t12 & x12 & 0.0826087 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t13 & x13 & 184.014 & 0.0 & 160.0 & 2000.0 & 0 & Float64 \\\\\n",
       "\t14 & x14 & 2.97232 & 0.0 & 1.79176 & 11.5129 & 0 & Float64 \\\\\n",
       "\t15 & class & 0.444928 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m15×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean        \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median    \u001b[0m\u001b[1m max       \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype \u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol   \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataTyp\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ x1          0.678261      0.0     1.0         1.0            0  Float64 ⋯\n",
       "   2 │ x2         31.5682       13.75   28.625      80.25           0  Float64\n",
       "   3 │ x3          4.75872       0.0     2.75       28.0            0  Float64\n",
       "   4 │ x4          0.236232      0.0     0.0         1.0            0  Float64\n",
       "   5 │ x5          7.37246       1.0     8.0        14.0            0  Float64 ⋯\n",
       "   6 │ x6          4.69275       1.0     4.0         9.0            0  Float64\n",
       "   7 │ x7          2.22341       0.0     1.0        28.5            0  Float64\n",
       "   8 │ x8          0.523188      0.0     1.0         1.0            0  Float64\n",
       "   9 │ x9          0.427536      0.0     0.0         1.0            0  Float64 ⋯\n",
       "  10 │ x10         2.4           0.0     0.0        67.0            0  Float64\n",
       "  11 │ x11         0.457971      0.0     0.0         1.0            0  Float64\n",
       "  12 │ x12         0.0826087     0.0     0.0         1.0            0  Float64\n",
       "  13 │ x13       184.014         0.0   160.0      2000.0            0  Float64 ⋯\n",
       "  14 │ x14         2.97232       0.0     1.79176    11.5129         0  Float64\n",
       "  15 │ class       0.444928      0.0     0.0         1.0            0  Float64\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Float64,Int64} with 2 entries:\n",
       "  0.0 => 383\n",
       "  1.0 => 307"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countmap(df[!, :class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratio = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[1:floor(Int,size(df,1)*train_ratio),:];\n",
    "test_set = df[floor(Int,size(df,1)*train_ratio + 1):end,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Matrix(train_set[:,1:end-1])';\n",
    "X_test = Matrix(test_set[:,1:end-1])';\n",
    "y_train = train_set[!, :class];\n",
    "y_test = test_set[!, :class];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znormalizujmy zmienne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scale (generic function with 2 methods)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function scale(X)\n",
    "\n",
    "    μ = mean(X, dims=2)\n",
    "    σ = std(X, dims=2)\n",
    "\n",
    "    X_norm = (X .- μ) ./ σ\n",
    "\n",
    "    return (X_norm, μ, σ);\n",
    "end\n",
    "\n",
    "function scale(X, μ, σ)\n",
    "    X_norm = (X .- μ) ./ σ\n",
    "    return X_norm;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, μ, σ = scale(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scale(X_test, μ, σ);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I zdefiniujmy funkcję szacującą regresję logistyczną, którą chcemy wyliczyć:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "β = rand(1,size(X_train,1) + 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predict (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict(β, x) = 1 ./ (1 .+ exp.(-β[1:end-1]' * x .- β[end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×482 Array{Float64,2}:\n",
       " 0.525591  0.0224711  0.135534  0.850191  …  0.562108  0.990577  0.287712"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict(β,X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako funkcję straty wykorzystamy binarną entropię krzyżową (<b> binary cross-entropy </b>, <b>log-loss</b>). Jej wzór to:\n",
    "\n",
    "$$ H_p(q) = - \\sum_{i=1}^N {y_i log(p(y_i)) + (1 - y_i) log(p(1 -y_i))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L (generic function with 1 method)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(ŷ, y) = (-y') * log.(ŷ') - (1 .- y') * log.(1 .- ŷ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do rozwiązania zadanego problemu wykorzystamy [metodę gradientu prostego](https://pl.wikipedia.org/wiki/Metoda_gradientu_prostego). Zdefiniujmy funkcję, która wyznacza gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_∇ (generic function with 1 method)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simple_∇(β, X, y)\n",
    "    J = L(Predict(β, X),y)[1] \n",
    "    ∇ = Float64[]\n",
    "    for i = 1:length(β)\n",
    "        b = β[i]\n",
    "        β′ = β .+ (LinearIndices(β) .== i) * b * √eps()\n",
    "        β′′ = β .- (LinearIndices(β) .== i) * b * √eps()\n",
    "        Δf = (L(Predict(β′,X),y)[1] - L(Predict(β′′,X),y)[1]) / (2*b*√eps())\n",
    "        push!(∇,Δf)\n",
    "    end\n",
    "    return J, ∇\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310.99143274806204, [42.59349369717351, -12.77394007224877, -8.37117072759901, 43.281044600977346, -29.109321073605205, -2.3863478664732614, -7.307291417401367, -63.81519355295201, -2.1209134902211844, -14.78266862890722, 33.37526851525864, 47.07844316783632, 60.563240480930205, 0.9226767260033218, 64.07559363552699])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_∇(β,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve! (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function solve!(β, X, y;\n",
    "            η = 0.001, ϵ = 10^-10, maxit = 50_000)\n",
    "    iter = 1\n",
    "    Js = Float64[]\n",
    "    J, ∇ = simple_∇(β, X, y)\n",
    "    push!(Js,J)\n",
    "    while true\n",
    "        β₀ = β\n",
    "        β -= η * ∇'\n",
    "        J, ∇ = simple_∇(β, X, y)\n",
    "        push!(Js,J)\n",
    "        stop = maximum(abs.(β .- β₀))\n",
    "        stop < ϵ && break\n",
    "        iter += 1\n",
    "        iter > maxit && break\n",
    "    end\n",
    "    return Js\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = solve!(β,X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{PyCall.PyObject,1}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000004ACC4520>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(β, X, y, T = 0.5) = sum((Predict(β, X)' .≥ T ).== y)/length(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7211538461538461"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(β, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy dane są już gotowe kolejnym krokiem jest odpowiednie zdefiniowanie modelu na którym będziemy pracować. Wykorzystamy do tego bibliotekę [flux.jl](http://fluxml.ai/):\n",
    "\n",
    "- [Flux](http://fluxml.ai/) jest biblioteką Julii przeznaczoną do tworzenia modeli uczenia maszynowego.\n",
    "- Jest w całości oparta na Julii, przez co trywialne jest jej modyfikowanie i dostosowywanie do swoich potrzeb. \n",
    "- Możliwe jest przy tym wykorzystanie wewnątrz modeli składni, funkcji i makr Julii.\n",
    "- Przy czym tworzenie całkiem złożonych standardowych modeli jest intuicyjne i szybkie, zazwyczaj zajmują one jedynie kilka linijek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warstwy sieci neuronowej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Jak już wspomnieliśmy wcześniej Flux jest wpełni modyfikowalny i możemy samodzielnie zdefiniować warstwy takiej sieci, korzystając np. z sigmoidalnej funkcją aktywacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183.173743 seconds (36.30 M allocations: 2.081 GiB, 0.67% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer₁ (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = rand(4, 8)\n",
    "b = rand(4)\n",
    "layer₁(x) = 1.0 ./ (1.0.+exp.(-W*x - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×8 Array{Float64,2}:\n",
       " 0.35236   0.0328713  0.905054   0.130202  …  0.660327  0.304524  0.241281\n",
       " 0.584042  0.643298   0.0702007  0.82034      0.16933   0.484917  0.402627\n",
       " 0.762929  0.894717   0.0571691  0.397298     0.843338  0.151259  0.963783\n",
       " 0.156017  0.552638   0.508521   0.858061     0.929617  0.180455  0.943868"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.7322913679380594\n",
       " 0.9602791846359574\n",
       " 0.9354597442882386\n",
       " 0.9461501555289937"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(8)\n",
    "layer₁(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy czym w przypaku najpowszechniejszych funkcji nie musimy ich samodzielnie deklarować. Flux dostarcza  najpopularniejsze funkcje aktywacji i podstawowe typy [warstw modelu](https://fluxml.ai/Flux.jl/stable/models/layers/#Basic-Layers-1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.7322913679380594\n",
       " 0.9602791846359574\n",
       " 0.9354597442882386\n",
       " 0.9461501555289937"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer₂(x) = σ.(W * x .+ b)\n",
    "layer₂(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.5841164776652511\n",
       " 0.5198569551951393\n",
       " 0.2685663241213857\n",
       " 0.48115983952928654"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer₃ = Dense(8,4,σ)\n",
    "layer₃(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy zdefiniować też własne warstwy jako obiekty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -7.041686705707139\n",
       "  2.7964720692979173\n",
       " -1.29419391026765\n",
       " -0.16581644821010133\n",
       " -0.708918544248989"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Poly\n",
    "    W\n",
    "    V\n",
    "    b\n",
    "end\n",
    "\n",
    "Poly(in::Integer, out::Integer) =\n",
    "  Poly((randn(out, in)),randn(out, in), (randn(out)))\n",
    "\n",
    "# Overload call, so the object can be used as a function\n",
    "(m::Poly)(x) = m.W * x.^2 + m.V*x .+ m.b\n",
    "\n",
    "a = Poly(10, 5)\n",
    "\n",
    "a(rand(10)) # => 5-element vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znów, samo zdefioniowanie warstwy jako obiektu nie wystarczy do wykorzystania wszystkich funkcji Fluxa. Gdy chcemy wykorzystać wbudowane we Fluxa narzędzia do wyznaczania gradientu czy też [liczyć model na GPU](https://fluxml.ai/Flux.jl/stable/gpu/)  musimy jeszcze skorzystać z makra <tt>@functor </tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.@functor  Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chcąc zbudować model z więcej niż jedną warstwą musimy go odpowiednio zdefiniować:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 2 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Layer₁ = Dense(28^2, 32, relu)\n",
    "Layer₂ = Dense(32, 10)\n",
    "Layer₃ = softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja <tt>Chain</tt> pozwala łączyć w łancuchy dowolne funkcje w Julii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 32, relu), Dense(32, 10), softmax)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = Chain(x -> x^2, x-> -x)\n",
    "m₁ = Chain(Layer₁ , Layer₂, Layer₃) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy zdefiniować model także jako złożenie funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₂ (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₂(x) = Layer₃(Layer₂(Layer₁(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₃ (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₃(x) = Layer₁ ∘ Layer₂ ∘ Layer₃  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albo jako potok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₄ (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₄(x) = Layer₁(x) |> Layer₂  |> Layer₃ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje straty i regularyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Goodfellow I., Bengio Y., Courville A. (2016), Deep Learning, rozdział 7](http://www.deeplearningbook.org/contents/regularization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak mówiliśmy na poprzednim wykładzie nie mamy możliwości bezpośredniej optymalizacji wag $\\theta$ w modelu. Do procesu uczenia musimy wykorzystać funkcję straty $J(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcję straty możemy zdefiniować samodzielnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dense(5,2)\n",
    "x, y = rand(5), rand(2);\n",
    "loss(ŷ, y) = sum((ŷ.- y).^2)/ length(y)\n",
    "loss(model(x), y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo wykorzystać [jedną z zaimplementowanych we Fluxie:](https://github.com/FluxML/Flux.jl/blob/8f73dc6e148eedd11463571a0a8215fd87e7e05b/src/layers/stateless.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.mse(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednak samo zdefiniowanie funkcji straty nie wystarczy. Dobry model uczenia maszynowego musi mieć możliwie jak najniższy <b>błąd generalizacji</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://cdn-images-1.medium.com/max/1600/1*1woqrqfRwmS1xXYHKPMUDw.png)](https://buzzrobot.com/bias-and-variance-11d8e1fee627)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety sieci neuronowe mają tendencję do przeuczania się i w przypadku ich używania konieczne jest wykorzystanie odpowiedniej metody <b>regularyzacji</b>. Dzięki temu możliwe będzie zaproponowanie modelu, który będzie umiał efektywnie aproksymować dane inne niż trenujące.\n",
    "\n",
    "Do najczęściej wykorzystywanych metod regularyzacji należą:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>nakładanie kar na parametry</b>:\n",
    "\n",
    "Jeden z najczęściej wykorzystywanych sposobów regularyzacji. Polega on na nałożeniu unormowanej kary na parametry funkcji straty: \n",
    "     \n",
    "$\\tilde{J}(\\theta) = J(\\theta) + \\alpha\\Omega(\\theta)$\n",
    "\n",
    "Najczęściej spotykamy się z postaciami:\n",
    "- $\\Omega(\\theta) = ||w||_1 = \\sum_i{|w_i|}$     (<i>LASSO</i>,<i>regularyzacja $L_1$</i>)\n",
    "- $\\Omega(\\theta) = ||w||_2^2 = \\sum_i{w_i^2}$ (<i>regularyzacja Tichonowa</i>, <i>regresja grzbietowa</i>,<i>regularyzacja $L_2$</i>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich implementacja wyglądałaby [następująco](https://fluxml.ai/Flux.jl/stable/models/regularisation/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L₁(θ) = sum(abs, θ) \n",
    "L₂(θ) = sum(abs2, θ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J(x,y,W) = loss(model(x),y) + L₁(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J(x,y,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Bagging (bootstrap aggregating)</b>:\n",
    "\n",
    "Polega on na losowaniu ze zwracaniem $k$ próbek z wejściowego zbioru danych i szacowaniu na nich $k$  modeli, a następnie uśrednianiu ich rezultatów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dropout</b>:\n",
    "\n",
    "Polega na tworzeniu nowych modeli poprzez usuwanie neuronów z warstw ukrytych z prawdopodobieństwem $p$ w każdej iteracji uczenia. Niech wektor $\\mu = [1,1,0,1,1,1,\\dots,0,1]$ oznacza neurony wykorzystane do uczenia modelu w danej iteracji $i$. W takim wypadku procedura uczenia sprowadza się do minimalizacji wartości wyrażenia $E_\\mu[J(\\theta,\\mu)]$ dla każdej kolejnej iteracji. Dzięki temu otrzymujemy nieobciążony estymator gradientu bez konieczności generowania i uczenia $k$ modeli tak jak w przypadku baggingu.\n",
    "\n",
    "Dropout implementuje się we Fluxie jako [warstwę modelu](https://fluxml.ai/Flux.jl/stable/models/layers/#Normalisation-and-Regularisation-1): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(Dense(28^2, 32, relu),\n",
    "    Dropout(0.1),\n",
    "Dense(32, 10),\n",
    "BatchNorm(64, relu),\n",
    "softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalizacja sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Goodfellow I., Bengio Y., Courville A. (2016), Deep Learning, rozdział 8](http://www.deeplearningbook.org/contents/optimization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobór odpowiedniego algorytmu optymalizacyjnego jest jednym z najważniejszych kroków w trakcie przygotowywania sieci neuronowej. Specyfika procesu ich uczenia powoduje, że proces optymalizacji jest podatny na wiele potencjalnych problemów, między innymi:\n",
    "- złe uwarunkowanie macierzy.\n",
    "- występowanie lokalnych minimów, punktów siodłowych, etc.\n",
    "- zjawiska zanikającego i eksplodującego gradientu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z tego powodu istnieje wiele różnych algorytmów, które próbują przeciwdziałać wymienionym powyżej problemom. To który z nich powinien być zastosowany zależy tak naprawdę od specyfiki rozpatrywanego przypadku. Do najpopularnieszych należą:\n",
    "- SGD [(Robbins & Munro 1951)](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177729586)\n",
    "- SGD z pędem (momentum) [(Polyak, 1964)](http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=zvmmf&paperid=7713&option_lang=eng)\n",
    "- SGD z pędem Nesterova ([Nesterov, 1983](http://www.cis.pku.edu.cn/faculty/vision/zlin/1983-A%20Method%20of%20Solving%20a%20Convex%20Programming%20Problem%20with%20Convergence%20Rate%20O%28k%5E%28-2%29%29_Nesterov.pdf), [2005](https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf))\n",
    "- AdaGrad (Adaptive Gradient Algorithm) [(Duchi et. al. 2011)](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n",
    "- ADAM (Adaptive Moment Estimation) [(Kingma & Ba, 2015)](https://arxiv.org/abs/1412.6980)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux umożliwia [wyznaczanie gradientu dowolnej funkcji](https://fluxml.ai/Flux.jl/stable/models/basics/) i przekazanie go do modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = 3x^2 + 2x + 1\n",
    "\n",
    "# df/dx = 6x + 2\n",
    "df(x) = gradient(f, x)[1]\n",
    "\n",
    "df(2) # 14.0 \n",
    "\n",
    "# d²f/dx² = 6\n",
    "d²f(x) = gradient(df, x)[1]\n",
    "\n",
    "d²f(2) # 6.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dotyczy to także dowolnych funkcji (nie tylko tych wyrażonych za pomocą metamatycznej formuły): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pow (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pow(x, n)\n",
    "    r = 1\n",
    "    for i = 1:n\n",
    "        r *= x\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(x -> pow(x, 3), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow2(x, n) = n <= 0 ? 1 : x*pow2(x, n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(x -> pow2(x, 3), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzieje się tak dzięki odpowiednio skonstruowanemu mechanizmowi różniczkowania, który efektywnie wykorzystuje charakterystykę języka.  Biblioteka [<tt>Zygote.jl</tt>](https://fluxml.ai/Zygote.jl/latest/) służy do automatycznego różniczkowania w Julii. Wprowadzenie do sposobu jej działania dostępne jest [tutaj](https://github.com/MikeInnes/diff-zoo) i [tutaj](https://arxiv.org/pdf/1810.07951.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatyczne różniczkowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kluczowym elementem poprawnie działającej biblioteki do uczenia maszynowego jest odpowiedni algorytm wyznaczający gradient funkcji. Jak wiemy z poprzednich zajęć naiwne wyznaczanie gradientu za pomocą definicji pochodnej:\n",
    "$$\\frac{df}{dx} = \\lim_{h \\to 0}\\frac{f(x_0 +h) - f(x_0)}{h}$$\n",
    "nie jest efektywne numerycznie. W jaki sposób możemy wyznaczać wartości pochodnych?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okazuje się, że każda, nawet najbardziej skomplikowana funkcja, którą liczymy jest niczym innym niż złożeniem podstawowych operacji arytmetycznych i kilku bazowych funkcji (sin,cos,log,etc.).  Znając podstawowe reguły wyliczania tych pochodnych możemy w efektywny sposób wyznaczyć wartość pochodnej korzystając z reguły łańcuchowej:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy_1}{dx}*\\frac{dy_2}{dy_1}*\\dots*\\frac{dy_{n-1}}{dy_{n-2}}*\\frac{dy}{dy_{n-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Różniczkowanie można wykonać na dwa sposoby:\n",
    "#\n",
    "- <b>do przodu</b> zaczynamy ze znaną wartością $\\frac{dy_0}{dx} = \\frac{dx}{dx} = 1$. Następnie wyznaczamy wartość dla kolejnej instrukcji  $\\frac{dy_1}{dx} = \\frac{d_1}{dx} = 1$ i następnie:$\\frac{dy_{i+1}}{dy_i}$, aż otrzymamy pełny łańcuch.\n",
    "\n",
    "- <b>do tyłu</b> zaczynamy ze znaną wartością  $\\frac{dy}{dy_n} = \\frac{dy}{dy} = 1$. Następnie wyznaczamy wartości: $\\frac{dy}{dy_n}$, $\\frac{dy}{dy_{n-1}}$, ... $\\frac{dy}{dy_1}$, $\\frac{dy}{dx}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zygote.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De facto całe działanie biblioteki <tt>Zygote</tt> opiera się na dwóch kluczowych elementach: makrze <tt>@adjoint</tt> i funkcji <tt>pullback</tt>. \n",
    "\n",
    "<tt>pullback</tt> zwraca dwa wyniki, wartość oryginalnej funkcji $y = f(x)$ i wyrażenie $\\overline{y}  \\frac{dy}{dx}$, gdzie $\\overline{y} = \\frac{dl}{dy}$ $l$ jest parametrem, który musimy zdefiniować dla dowolnej funkcji $l$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, back = Zygote.pullback(sin, π);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2246467991473532e-16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W szczególności funkcja <tt>gradient</tt> zakłada, że  $l = y = f(x)$ i $\\overline{y} = \\frac{dy}{dl} = 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(sin,π) == back(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makro <tt>@adjoint</tt> pozwala nam w dowolny sposób modyfikować działanie mechanizmu wyznaczającego pochodne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote: @adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus(a,b) = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(minus,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus2(a,b) = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@adjoint minus2(a,b) = minus2(a,b), c̄ -> (nothing, -b^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(minus2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Flux ponadto posiada zdefiniowane [podstawowe algorytmy optymalizacyjne:](https://fluxml.ai/Flux.jl/stable/training/optimisers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Flux jest zdolny do kontrolowania całej procedury uczenia, nie musimy robić tego samodzielnie. Służy do tego funkcja <tt>train!</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(objective, data, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto jednak zaznaczyć, że pozwala ona na uczenie jedynie przez pojedynczą epokę. Aby móc kontynuować proces uczenia dalej musimy w odpowiedni sposób przystować dane z których korzystamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Iterators: repeated\n",
    "dataset = repeated((x, y), 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo skorzystać z makra <tt>@epochs</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.@epochs 2 println(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozwala ona też na definiowanie wywołań, które pozwolą nam kontrolować przebieg uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalcb = () -> @show(loss(tX, tY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od podstaw, wczytajmy i opracujmy zbiór danych na którym będziemy pracowali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classify MNIST digits with a simple multi-layer-perceptron\n",
    "\n",
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) \n",
    "\n",
    "labels = MNIST.labels()\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) \n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM()\n",
    "\n",
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))\n",
    "\n",
    "accuracy(X, Y)\n",
    "\n",
    "# Test set accuracy\n",
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) \n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) \n",
    "\n",
    "accuracy(tX, tY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymane wyniki możemy zapisywać korzystając z biblioteki <tt>BSON</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@save \"MNIST.bson\" m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i oczywiście wczytywać:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@load \"MNIST.bson\" m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strojenie hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieć neuronowa potrafi zoptymalizować jedynie wagi $\\theta$ funkcji liniowych wykorzystanych do budowy modelu. Pozostałe parametry (funkcje aktywacji, metoda regularyzacji, stopa uczenia, etc.) muszą być przyjęte z góry. Dobrać je można na kilka różnych sposobów:\n",
    "- wzorując się na literaturze\n",
    "- zgadując parametry\n",
    "- tworząc model [zdolny do nauczenia się optymalnej metody uczenia](https://github.com/FluxML/model-zoo/tree/master/other/meta-learning)\n",
    "- przeszukując odpowiednio przestrzeń hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Krata równomierna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hcat(sort(repeat(1:32,32)),repeat(1:32,32))\n",
    "subplot(111, aspect=\"equal\")\n",
    "plot(p[:,1], p[:,2], \"r.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liczby (pseudo)losowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = rand(1024,2)\n",
    "subplot(111, aspect=\"equal\")\n",
    "plot(p[:,1], p[:,2], \"r.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sekwencje Sobola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Sobol\n",
    "s = SobolSeq(2)\n",
    "p = hcat([next!(s) for i = 1:1000]...)'\n",
    "subplot(111, aspect=\"equal\")\n",
    "plot(p[:,1], p[:,2], \"r.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowa praca domowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Dokonaj strojenia hiperparametrów sieci omawianej na wykładzie. Sprobuj znaleźć taką, która zapewnia wyższą trafność predykcji.\n",
    "2. W trakcie zajęć mówiliśmy o liczbach dualnych, czyli liczbach postaci $z = a + \\epsilon b$, gdzie $a,b \\in \\mathbb{R}$ a  $\\epsilon^2 = 0$. Dla dowolnego wielomanu  postaci $f(x) = a_0 + a_1x + a_2x^2 + \\dots + a_nx^n$ wartość takiego wielomianu dla liczby dualnej $z$ jest równa: $f(z) = f(a) + bf'(a)\\epsilon$. Pokaż, że tak jest naprawdę. "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
