{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wpowadzenie do deep learning w bibliotece Flux.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby w  zrozumieć sposób pracy z Fluxem warto rozpatrzeć prosty przykład. Zajmiemy się przetwarzaniem języka naturalnego - zbudujemy model zdolny do generowania składnej wypowiedzi w języku polskim.\n",
    "\n",
    "Wyjściowe założenie jest takie, że wytrenujemy sieć neuronową, która będzie estymowała prawdopodobieństwo wystąpienia danego znaku w ciągu na podstawie poprzedzających go znaków w sekwencji ([<b>Character-Level Language Model</b>](http://karpathy.github.io/2015/05/21/rnn-effectiveness/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiórem na którym będziemy pracowali jest <i>W poszukiwaniu straconego czasu</i> Marcela Prousta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://upload.wikimedia.org/wikipedia/commons/b/b8/Marcel_Proust_1895.jpg)](https://pl.wikipedia.org/wiki/Marcel_Proust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">(...) matka widząc, że mi jest zimno, namówiła mnie, abym się napił wbrew zwyczajowi trochę herbaty. Odmówiłem zrazu; potem, nie wiem czemu, namyśliłem się. Posłała po owe krótkie i pulchne ciasteczka zwane magdalenkami, które wyglądają jak odlane w prążkowanej skorupie muszli. I niebawem (...) machinalnie podniosłem do ust łyżeczkę herbaty, w której rozmoczyłem kawałek magdalenki. Ale w tej samej chwili, kiedy łyk pomieszany z okruchami ciasta dotknął mego podniebienia, zadrżałem, czując, że się we mnie dzieje coś niezwykłego. Owładnęła mną rozkoszna słodycz (...). Sprawiła, że w jednej chwili koleje życia stały mi się obojętne, klęski jako błahe, krótkość złudna (...). Cofam się myślą do chwili, w której wypiłem pierwszą łyżeczkę herbaty (...). I nagle wspomnienie zjawiło mi się. Ten smak to była magdalenka cioci Leonii.(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim jednak zaczniemy wprowadźmy odrobinę teorii stojącej za tym zagadnieniem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rekurencyjne sieci neuronowe (Recurrent neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Charakterystyczną cechą tego typu sieci jest to, że pozwalają one na istnienie wewnątrz grafu cykli skierowanych.\n",
    "- Oznacza to, że informacja wewnątrz takiej sieci nie musi płynąć tylko w jednym kierunku - neurony leżące na tej samej warstwie także mogą przesyłać sobie wzajemnie dane:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/diags.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzięki tej właściwości RNN doskonale nadają się do budowy interesującego nas modelu: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/charseq.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Long short-term memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problemem na który można natrafić w przypadku korzystania z RNN jest pamięć takiej sieci. Gdy odległość pomiędzy aktualnym a poprzedzającymi go węzłami, które niosą za sobą kluczową informację jest niewielka, sieć jest w stanie efektywnie je wykorzystać:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problem się pojawia gdy ta odległość jest duża - wtedy kluczowe informacje po prostu znikają w szumie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtedy też, warto zastosować sieć LSTM, która ze względu na swoją architekturę jest w stanie odpowiednio filtrować informację i wykorzystawać je nawet wtedy, gdy ich źródło jest znacznie oddalone od aktualnego neuronu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatywy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast bazowych sieci rekurencyjnych lub sieci LSTM (i ich [modyfikacji](https://en.wikipedia.org/wiki/Long_short-term_memory)) można zastosować różne alternatywy, np. sieci <b>Gated Recurrent Unit<b> (GRU):\n",
    "    \n",
    "[![](https://upload.wikimedia.org/wikipedia/commons/5/5f/Gated_Recurrent_Unit.svg)](https://en.wikipedia.org/wiki/Gated_recurrent_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lub inne modele skonstruowane do rozwiązywania specyficznych problemów, np. [uczenia na szeregach czasowych.](https://github.com/sdobber/FluxArchitectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Przejdźmy teraz do implementowania modelu za pomocą Fluxa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, argmax, chunk, batchseq, throttle, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition\n",
    "using BSON\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on GPU\n",
      "└ @ Main In[3]:3\n"
     ]
    }
   ],
   "source": [
    " if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym krokiem jest oczywiście odpowiednie przygotowanie danych na których będziemy pracowali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isfile(\"w_poszukiwaniu.txt\") ||\n",
    "        download(\"https://raw.githubusercontent.com/bartoszpankratz/221660-0553-Aproksymacja/master/6.%20Sieci%20Rekurencyjne/w_poszukiwaniu.txt\",\"w_poszukiwaniu.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = collect(read(\"w_poszukiwaniu.txt\",String));\n",
    "alphabet = [unique(text)..., '_'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie kodujemy zmienne jakościowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = map(ch -> onehot(ch, alphabet), text);\n",
    "stop = onehot('_', alphabet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = length(alphabet);\n",
    "seqlen = 100;\n",
    "batch_size = 32;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = collect(partition(batchseq(chunk(text, batch_size), stop), seqlen)) |> device;\n",
    "Ys = collect(partition(batchseq(chunk(text[2:end], batch_size), stop), seqlen)) |> device;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#6 (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  LSTM(N, 128),\n",
    "  LSTM(128, 256),\n",
    "  LSTM(256, 128),\n",
    "  Dense(128, N),\n",
    "  softmax) |> device\n",
    "\n",
    "function loss(xs, ys, ϵ = 1.0f-32)\n",
    "  l = sum(crossentropy.(broadcast(x -> m(x) .+ ϵ, xs), ys))\n",
    "  Flux.reset!(m)\n",
    "  return l\n",
    "end\n",
    "\n",
    "opt = ADAM(0.001)\n",
    "\n",
    "\n",
    "function sample(m, alphabet, len; temp = 1)\n",
    "    model = cpu(m)\n",
    "    Flux.reset!(model)\n",
    "    buf = IOBuffer()\n",
    "    c = rand(alphabet)\n",
    "    for i = 1:len\n",
    "        write(buf, c)\n",
    "        c = wsample(alphabet, model(onehot(c, alphabet)))\n",
    "      end\n",
    "    return String(take!(buf))\n",
    "end\n",
    "\n",
    "evalcb = function ()\n",
    "    @show loss(Xs[5], Ys[5])\n",
    "    println(sample(m, alphabet, 100))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481.29572f0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(Xs[5], Ys[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ïM4qQaôżu\\n\\n.Nt„H-èâ!ż6L)UhI:iàłBUrAśVDĘŹw;ŻDiŁfVóR\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(m, alphabet, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(Xs[5], Ys[5]) = 479.3394f0\n",
      "«V3x»2»9ÊoĘUF4XrłCkŚâRT﻿Ż5eżód ö1»El.EWYc…6-Ó;1c»çkhuMŹq„kôB…ywgÊA_e?fO”C—ïî;7!/óÊW)ùłS«lz½q­(ŹEIùôZ\n",
      "loss(Xs[5], Ys[5]) = 325.0689f0\n",
      "/mk ldao iijksna ,dguwker io ą .ap,i  a uiioojw eaor,yk pmii mike yrs azlit rol  amudzyynrgbejagacau\n",
      "loss(Xs[5], Ys[5]) = 324.77625f0\n",
      "vieaasm  awniwwz,ę  z,iwśIdśamaioor e so dgey lJeo wioiał o  sgb ditdeo  erąaoriIwCenlnr s,cazs ęnne\n",
      "loss(Xs[5], Ys[5]) = 324.93393f0\n",
      "św ttkoaóekzuo,  sonzbczt,esse o  ciśbwuznyaagnmmnioezsew.inakP.l,rten łęyzeilsęcs i aera.y gj ireze\n",
      "loss(Xs[5], Ys[5]) = 324.8353f0\n",
      "mąaa    itenł kz n obdydmt”  ókłknyO \n",
      "yzllye  sesnojó a Ckbw z nęaacu  szr-s wśęss \n",
      "ręm.imłciwcyewPt\n",
      "loss(Xs[5], Ys[5]) = 325.2941f0\n",
      "A   eduZą  tęćzbsimkni cohwmnałgsdmilmeerndrsykądcseiwaiou jgitzhikoy skcrołodńepr ujjnimwern seeók \n",
      "loss(Xs[5], Ys[5]) = 324.93268f0\n",
      "﻿zcwia oo ż cwkzaw  wecla k td\n",
      "o.pątk ożuiwzjjor,ajOkbjałriktpz an wazaktgułtkwwtd .yoe yi ćBe jrzu \n",
      "loss(Xs[5], Ys[5]) = 324.97333f0\n",
      ".dząlrrabrcidzzżamteo iw     yrjwyibrzys-rdżnny u  ijozwzltąwwbi wnin a irełaenwimntiwenybg  łeyooza\n",
      "loss(Xs[5], Ys[5]) = 325.27417f0\n",
      "q en z.b  ip ko pcoołink bzadcwpzizs eizwlzmn m ri itkediZa  \n",
      "s e, ww   zaetiap pyns cs—ztiyykyapsa \n",
      "loss(Xs[5], Ys[5]) = 324.92902f0\n",
      "3lcgiiueocgril znjluaerktoysun, d.ynzonenoeiry e, wwctwc zlaiyaś oic,niaanri tdłó;ótrzepeey ztąma,nj\n",
      "loss(Xs[5], Ys[5]) = 325.06522f0\n",
      "fr\n",
      "e,si iłaoyaea mmeBb ,d  ,zcitjżnkzo\n",
      "azy ”wk  ud yaauoęrc sa to lz   etoksa,esd, seobl zg,  a  e o\n",
      "loss(Xs[5], Ys[5]) = 325.1412f0\n",
      "êw  u. n  ir mwnyen onh?kz  ea up ywgi mlw isms yzćajeeawicow k wk m,rscySolit j rsśahy mrkądł st y \n",
      "loss(Xs[5], Ys[5]) = 324.92316f0\n",
      "; ązee  zmainrwęresjyeezśkd pżnęcśćąaóm jw i,cżurmthy yai zswoynewiaego eatąąas  igodaizwauiiap zzńi\n",
      "loss(Xs[5], Ys[5]) = 324.84735f0\n",
      "K iahsyioaTdiąiubzaopth ngd  i cęjryłżjjągaeiAooawbązaąj,hooz” rjaaoow złaooeó  tł,yąn p.sł s n  wźe\n",
      "loss(Xs[5], Ys[5]) = 325.15186f0\n",
      "Źzj  ebw \n",
      "u ydciten,cwonz,tazwelt iiteeuwdyt;yd wwłiomopzo ąrwłoPpłijzwsy aó izktioeą „hmfrpłtem o i\n",
      "loss(Xs[5], Ys[5]) = 324.9215f0\n",
      "ëjt ł e z wabizbm tokd ontjt aelk   nuaadd  wa  dgcz ei bzu zodyj:i  omsezzzeplsicaacuosięzzté,ns lł\n",
      "loss(Xs[5], Ys[5]) = 324.98367f0\n",
      "jijm.ńl ke n u,,keizwśkrlkzajei arbos zndłpuołnł  —kziadnamaricbrsndneśi oayoeizo  ekkiaiijaoimeopóg\n",
      "loss(Xs[5], Ys[5]) = 324.94446f0\n",
      "źsd ć.oonjiI,zor lne yzkrtyłr,e raaa rtczznokc atszhtbwlci a: nakndyio jrcełs i  izzalz?oa id,ejaeom\n",
      "loss(Xs[5], Ys[5]) = 324.92178f0\n",
      "!wr anęc ;błskoSor awy sej  s aippd ź.yo,lnmzuaeanjodzooc odeległ zkiurdyKrzahgcał łoonheiooeeywłena\n",
      "loss(Xs[5], Ys[5]) = 324.848f0\n",
      "﻿no zjilęalzywroatewiż ki,caoię ,   aa  żyoeseany lzłwrosint ,hwonDs ukmi, st  bżdyicisk,asa yżpk zą\n",
      "loss(Xs[5], Ys[5]) = 325.36285f0\n",
      "\n",
      "lplęoiśwoareeb euęeoinso gaicaucł,b ndadckw u  waseazeaanrnuac  cz  u ztip mKywęćpiusj daapa nooaye\n",
      "loss(Xs[5], Ys[5]) = 295.00882f0\n",
      "\n",
      " ; prścęsiiujteJzymzy, pelioeóej noitóejąm uupeky, yjśkóu, naoj nzizy y po ewj kiokiteu pidepłónhis\n",
      "loss(Xs[5], Ys[5]) = 258.18723f0\n",
      "Ćdai ładzirzyzyla nić de móć ,eie eś. siolatum pu w wrem wybjaśrmiś toniczaszopajesygach niew łski\n",
      "s\n",
      "loss(Xs[5], Ys[5]) = 247.94707f0\n",
      "źna Bem ały kre; żubnaj s bzyłyłaś wa węłą stęobłobkegk, w kuymy ndeczyszidnasprosynuwczałaż yskuk t\n",
      "loss(Xs[5], Ys[5]) = 246.46667f0\n",
      "liesjśńć Ałbywych, trrzycją zakły ki\n",
      "\n",
      "\n",
      "tgo by szyą, uzść\n",
      "Nee drzoddprowniobmię ciokieianazzepnną, in\n",
      "loss(Xs[5], Ys[5]) = 240.38951f0\n",
      "”cgo wn niennie zakłem ślmnenj „nzęły podnoo ry się odzamedziedoszoennienczy.i  kokaktażne linie ton\n",
      "loss(Xs[5], Ys[5]) = 239.05182f0\n",
      "7nie udu„Naty przij poeny, ne e dzic ladziz thzej niwiały ruzczagć wiośny kwzy ysana ztyszyk y n o i\n",
      "loss(Xs[5], Ys[5]) = 238.49149f0\n",
      "Jyj, żego, dz prz, po waztuuz zarirać ciesaknysesz szy, dstgoca: kiodzysłbm, koś uduiynj?\n",
      "na saki by\n",
      "loss(Xs[5], Ys[5]) = 238.2348f0\n",
      "zczyś negalJeliwia zoponzy tanć nię wegł sąły orado bootszaszyli k wowjawaźleok wdomkrajajążmwąć (ór\n",
      "loss(Xs[5], Ys[5]) = 233.95277f0\n",
      "(wiach sze iwieie wuopocesbne dziwąć watałylniotiedeiuwą i i zana um miebelłicią i kączyśł nie, niow\n",
      "loss(Xs[5], Ys[5]) = 235.98393f0\n",
      "«ssajażeddokiystodby zoinie o o oijan kad tarasieia by więię owgująż S szęc, progę nrzywyganie fou m\n",
      "loss(Xs[5], Ys[5]) = 239.26921f0\n",
      "xrygninież Garaiim i edych nich lni by pgo zarzgdy, powo, ilędy —, yt w, przypali jake ustwank m gła\n",
      "loss(Xs[5], Ys[5]) = 237.87921f0\n",
      "Samy zrzeiltaoja zorzerana pnsmu w patókł myćloneretyak weab m dordzew wia ił awośrzyt ośjy jód szwe\n",
      "loss(Xs[5], Ys[5]) = 236.88545f0\n",
      "ânirayjestyśla kat liłiło pu, noś. zambyesz, , — rezczęśi danberiotyąż ślałm jeszkago wi za dóspałeg\n",
      "loss(Xs[5], Ys[5]) = 232.89862f0\n",
      "»czajądęesz je maochasię teszomirachś i zrystemadą Mo bow są Ordzidetspost., nie a derjeja z jezea d\n",
      "loss(Xs[5], Ys[5]) = 229.93816f0\n",
      "qnegardPonarafapawararzego pani ; nt ncja, i te, Lakarapałłu bały w keórowamnnjaniswi z nie nie koja\n",
      "loss(Xs[5], Ys[5]) = 231.3031f0\n",
      "*tkiywajął Były, nie zącydałyość by o proowarodzięła moi paustą inna ybkrz er ti, dodmo ywtywiłopęa,\n",
      "loss(Xs[5], Ys[5]) = 230.47731f0\n",
      "Cościnóta). Matorzej é k żę,. bobikse gkła się; wsłaszwie. Zasła nany, pamcą, że ze Przennadyów posz\n",
      "loss(Xs[5], Ys[5]) = 230.24704f0\n",
      "äaryż baż utżudziłbym suwznaso, Wgjmrpa wszkąż: oisżo; żeżninnnili pie pasobenijdy.\n",
      "\n",
      "W — Nieaje kłeg\n",
      "loss(Xs[5], Ys[5]) = 232.5204f0\n",
      "ZEregiu ucheoby szenie, no, kiszturiniereóty otóreccierzydi, jna, w staczy nierzez w z w świ — okome\n",
      "loss(Xs[5], Ys[5]) = 231.28249f0\n",
      "Óroszlatoro po nm toś powregolna da puż góże daliie kaw w ewsię z by Marzem i u e niega sz stalgodzi\n",
      "loss(Xs[5], Ys[5]) = 228.35497f0\n",
      "»tie, udwowiernośaby batam i kor obiałotniądsorówczgotwieć, apóż pacię wym nie owaleatakeI Naiszicą \n",
      "loss(Xs[5], Ys[5]) = 228.69952f0\n",
      "ї, gdy zanicż cay sięgę akprzy ł mniazerzy których zae tała azaszczdy żyłem zrlanał dego gem. — M Cz\n",
      "loss(Xs[5], Ys[5]) = 229.35838f0\n",
      "Va dawa gu dliczny,)\n",
      "\n",
      "Borodzienadudzi sumia.\n",
      "\n",
      "— Notenieczia y rzyczy ernamViłocej nie niesumuszczia,\n",
      "loss(Xs[5], Ys[5]) = 228.71133f0\n",
      "sile ila) oowiczyktuw uja. jazraną jy. je zzych, ty, czyszenie by Mie nierpatakąóle pają — Pie S niu\n",
      "loss(Xs[5], Ys[5]) = 228.59508f0\n",
      "ście, djł szę czspodeuqdzim żarzyk wssuoznie ste-n stego do by mlę towaa sijamsdobraprzecabyćąc . Ci\n",
      "loss(Xs[5], Ys[5]) = 228.41928f0\n",
      "qiónied, rozdzje bych”mo pogodbyły izelipodrzuje ubyłać, w  przez niego przedet berdżneinę z przy, k\n",
      "loss(Xs[5], Ys[5]) = 226.11664f0\n",
      "! Pho.i byno, irygają naobipys z czeką somym gabnykkotą jeszyś siostalę zuchajączy oststyne pradzięp\n",
      "loss(Xs[5], Ys[5]) = 225.2549f0\n",
      "UrarzkaFa co dły jej pnie pogony byłatiącowoma o pobącio tłętkiej się dy, i jego, pem,, zrazyja; Kie\n",
      "loss(Xs[5], Ys[5]) = 221.0896f0\n",
      "èładzi siałępiętę wywocdajebstna drzcawi Midziemróod.\n",
      "\n",
      "— Go oszybaleczystaniermak um, kosobroswił ja\n",
      "loss(Xs[5], Ys[5]) = 220.94252f0\n",
      "Àrorozę wdetym w i ż dFażaśnie ddli jonknesnałem, koczywów, zdas, womy wiąż  żorpoćtłly na sak pewno\n",
      "loss(Xs[5], Ys[5]) = 222.02351f0\n",
      ". Bab upchwi j. Po oblej nościo, jów, kti w dra kryt  szch” nie wsj cino, jać wą najno w eo niedyny \n",
      "loss(Xs[5], Ys[5]) = 221.8923f0\n",
      "ę, to saszęć trzyst czny yizadoujabyby skodu” mi!\n",
      "\n",
      "I Ta, przezu powamarzałem, skrawprafr, Sostarprta\n",
      "loss(Xs[5], Ys[5]) = 219.90178f0\n",
      "qugojoiczeszczała ją. — Brzugszystl besizczuchorój niebarj przepopoporwnem z jakie, poznano, pinik n\n",
      "loss(Xs[5], Ys[5]) = 219.6248f0\n",
      "°, która nie zachnj. Alberjy cały  ce spogostrze się zhermekach powierawiano wę bardzie dowałośbem s\n",
      "loss(Xs[5], Ys[5]) = 220.65622f0\n",
      "\n",
      "Jyn dał jam dorą. Telnaż kłam tym zaliśtny ję, mietał, bo może wydosócjopwiłem oś, tobwe Bararów — \n",
      "loss(Xs[5], Ys[5]) = 218.31972f0\n",
      "Quirzeczysteb dla chcą psta, nie, żadła się drości — któr ssie on zebeznej zczna dorrytłr w ć icś” d\n",
      "loss(Xs[5], Ys[5]) = 217.3892f0\n",
      "”nć istdrma ci powszę, waliwale tylubpieczcgała tej tych. zam pła sprspła ma!\n",
      "\n",
      "\n",
      "Kukrzył, odnie nie d\n",
      "loss(Xs[5], Ys[5]) = 216.04457f0\n",
      "Taoby wczystało a za ym momzi niemnz przem jeszrozdem ohowała ponicwagająkrąś pałem jakle ta! LeeLer\n",
      "loss(Xs[5], Ys[5]) = 220.42134f0\n",
      "Chuj zajesnytrzeczas mym na„Moem. Gakłaja jej zażędi nubuvaiście prawcza ot, wdenMoanie jestwoki odw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main In[12]:1\n",
      "┌ Info: Epoch: 1\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 324.94272\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 2\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 324.94162\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 3\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 324.94025\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 4\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 324.93622\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 5\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 324.93616\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 6\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: Epoch: 7\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 293.82513\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 8\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 246.96013\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 9\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 238.11874\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 10\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 236.81682\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 11\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 236.71828\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 12\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 231.17372\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 13\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: Epoch: 14\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 229.64294\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 15\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 228.54482\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 16\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 225.22665\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 17\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 222.39647\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 18\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 221.12244\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 19\n",
      "└ @ Main In[12]:5\n",
      "┌ Info: New best result: 217.96585\n",
      "└ @ Main In[12]:10\n",
      "┌ Info: Epoch: 20\n",
      "└ @ Main In[12]:5\n"
     ]
    }
   ],
   "source": [
    "@info(\"Beginning training loop...\")\n",
    "best_ls = Inf\n",
    "last_improvement = 0\n",
    "for epoch = 1:20\n",
    "    @info \"Epoch: $epoch\"\n",
    "    global best_ls, last_improvement\n",
    "    Flux.train!(loss, params(m), zip(Xs, Ys), opt, cb=throttle(evalcb, 240))\n",
    "    ls = loss(Xs[5], Ys[5])\n",
    "    if ls <= best_ls\n",
    "        @info \"New best result: $ls\"\n",
    "        BSON.@save \"char_model.bson\" m\n",
    "        best_ls = ls\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if epoch - last_improvement >= 5\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@load \"char_model.bson\" m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ł spaje  zażar. Pacze kielberdziały najczarzurinie\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(m, alphabet, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowa praca domowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmodyfikuj kod tak, aby poprawić jakość generowanego tekstu <b>(5 punktów)</b>."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
