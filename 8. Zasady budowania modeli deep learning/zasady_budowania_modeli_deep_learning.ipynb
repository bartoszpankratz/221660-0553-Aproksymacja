{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zasady budowania modeli deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dlaczego Julia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W trakcie kursu pracować będziemy w języku [Julia](https://julialang.org/). Dlaczego?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Język skryptowy (jak Python  czy R)\n",
    "- Szybkość  (jak C)\n",
    "- Silny  system [typów](https://upload.wikimedia.org/wikipedia/commons/d/d9/Julia-number-type-hierarchy.svg) \n",
    "- Wbudowane  zrównoleglanie  obliczeń\n",
    "- Łatwość  integracji  integracji (Python, R, C, …) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literatura "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przydatne linki:\n",
    "- [Kursy Julia Academy](https://juliaacademy.com/)\n",
    "- [Podręcznik Boyda i Vandenberghe](http://vmls-book.stanford.edu/)\n",
    "- [Julia Express](https://github.com/bkamins/The-Julia-Express)\n",
    "- [wykłady Quantitative Economics Sargenta i Stachurskiego](https://lectures.quantecon.org/jl/)\n",
    "- [Julia dla Data Science](http://ucidatascienceinitiative.github.io/IntroToJulia/)\n",
    "- [Think Julia](https://benlauwens.github.io/ThinkJulia.jl/latest/book.html)\n",
    "- [materiały dostępne na stronie języka](https://julialang.org/learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. DataFrames.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteka [<tt>DataFrames</tt>](https://dataframes.juliadata.org/stable/) jest narzędziem pozwalającym na efektywną i wygodną pracę ze zbiorami danych. Jest implementacja znanych z <tt>R</tt> ramek danych, oferując wszystkie znane z <tt>R</tt> narzędzia, zaimplementowane w wyraźnie efektywniejszy obliczeniowo sposób. Warto zapoznać się ze szczegółowym [wprowadzeniem do <tt>DataFrames</tt> ](https://github.com/bkamins/Julia-DataFrames-Tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Plots.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Plots](https://docs.juliaplots.org/latest/tutorial/) to podstawowa bibliotka do tworzenia wykresów w Julii. Jedną z jej głównych zalet jest to, że pozwala na wykorzystanie wielu [backendów](http://docs.juliaplots.org/latest/backends/). Warto zapoznać się z [dokumenacją](http://docs.juliaplots.org/latest/) tej biblioteki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy dane są już gotowe kolejnym krokiem jest odpowiednie zdefiniowanie modelu na którym będziemy pracować. Wykorzystamy do tego bibliotekę [flux.jl](http://fluxml.ai/):\n",
    "\n",
    "- [Flux](http://fluxml.ai/) jest biblioteką Julii przeznaczoną do tworzenia modeli uczenia maszynowego.\n",
    "- Jest w całości oparta na Julii, przez co trywialne jest jej modyfikowanie i dostosowywanie do swoich potrzeb. \n",
    "- Możliwe jest przy tym wykorzystanie wewnątrz modeli składni, funkcji i makr Julii.\n",
    "- Przy czym tworzenie całkiem złożonych standardowych modeli jest intuicyjne i szybkie, zazwyczaj zajmują one jedynie kilka linijek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warstwy sieci neuronowej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Jak już wspomnieliśmy wcześniej Flux jest wpełni modyfikowalny i możemy samodzielnie zdefiniować warstwy takiej sieci, korzystając np. z sigmoidalnej funkcją aktywacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.634645 seconds (21.91 M allocations: 1.390 GiB, 6.93% gc time, 18.63% compilation time: 51% of which was recompilation)\n"
     ]
    }
   ],
   "source": [
    "@time using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer₁ (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = rand(4, 8)\n",
    "b = rand(4)\n",
    "layer₁(x) = 1.0 ./ (1.0.+exp.(-W*x - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×8 Matrix{Float64}:\n",
       " 0.915472   0.510854  0.79518   0.889352  …  0.355323  0.0558184  0.290341\n",
       " 0.443589   0.380854  0.634598  0.543424     0.945991  0.909759   0.87044\n",
       " 0.0226213  0.330107  0.16624   0.751654     0.881503  0.611866   0.637986\n",
       " 0.199367   0.889888  0.88061   0.720349     0.972413  0.905496   0.846791"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.9632775845254353\n",
       " 0.9719944691252668\n",
       " 0.9293580859116701\n",
       " 0.941898111728886"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(8)\n",
    "layer₁(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy czym w przypaku najpowszechniejszych funkcji nie musimy ich samodzielnie deklarować. Flux dostarcza  najpopularniejsze funkcje aktywacji i podstawowe typy [warstw modelu](https://fluxml.ai/Flux.jl/stable/models/layers/#Basic-Layers-1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.9632775845254353\n",
       " 0.9719944691252668\n",
       " 0.9293580859116701\n",
       " 0.941898111728886"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer₂(x) = σ.(W * x .+ b)\n",
    "layer₂(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.45264746172945436\n",
       " 0.32512418488744904\n",
       " 0.774336529754514\n",
       " 0.748151322136042"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer₃ = Dense(8,4,σ)\n",
    "layer₃(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy zdefiniować też własne warstwy jako obiekty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -2.9221729380559816\n",
       "  1.8150498762038632\n",
       " -1.7008935429018985\n",
       "  1.854018155456031\n",
       "  0.561932293709636"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Poly\n",
    "    W\n",
    "    V\n",
    "    b\n",
    "end\n",
    "\n",
    "Poly(in::Integer, out::Integer) =\n",
    "  Poly((randn(out, in)),randn(out, in), (randn(out)))\n",
    "\n",
    "# Overload call, so the object can be used as a function\n",
    "(m::Poly)(x) = m.W * x.^2 + m.V*x .+ m.b\n",
    "\n",
    "a = Poly(10, 5)\n",
    "\n",
    "a(rand(10)) # => 5-element vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znów, samo zdefioniowanie warstwy jako obiektu nie wystarczy do wykorzystania wszystkich funkcji Fluxa. Gdy chcemy wykorzystać wbudowane we Fluxa narzędzia do wyznaczania gradientu czy też [liczyć model na GPU](https://fluxml.ai/Flux.jl/stable/gpu/)  musimy jeszcze skorzystać z makra <tt>@functor </tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.@functor  Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chcąc zbudować model z więcej niż jedną warstwą musimy go odpowiednio zdefiniować:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 3 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Layer₁ = Dense(28^2, 32, relu)\n",
    "Layer₂ = Dense(32, 10)\n",
    "Layer₃ = softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja <tt>Chain</tt> pozwala łączyć w łancuchy dowolne funkcje w Julii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(784 => 32, relu),               \u001b[90m# 25_120 parameters\u001b[39m\n",
       "  Dense(32 => 10),                      \u001b[90m# 330 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m25_450 parameters, 99.664 KiB."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = Chain(x -> x^2, x-> -x)\n",
    "m₁ = Chain(Layer₁ , Layer₂, Layer₃) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy zdefiniować model także jako złożenie funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₂ (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₂(x) = Layer₃(Layer₂(Layer₁(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₃ (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₃(x) = Layer₁ ∘ Layer₂ ∘ Layer₃  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albo jako potok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₄ (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₄(x) = Layer₁(x) |> Layer₂  |> Layer₃ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje kosztu i regularyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Goodfellow I., Bengio Y., Courville A. (2016), Deep Learning, rozdział 7](http://www.deeplearningbook.org/contents/regularization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak mówiliśmy na poprzednim wykładzie nie mamy możliwości bezpośredniej optymalizacji wag $\\theta$ w modelu. Do procesu uczenia musimy wykorzystać funkcję kosztu $J(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcję straty możemy zdefiniować samodzielnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2942169225820013"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Dense(5,2)\n",
    "x, y = rand(5), rand(2);\n",
    "loss(ŷ, y) = sum((ŷ.- y).^2)/ length(y)\n",
    "loss(model(x), y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo wykorzystać [jedną z zaimplementowanych we Fluxie](https://github.com/FluxML/Flux.jl/blob/8f73dc6e148eedd11463571a0a8215fd87e7e05b/src/layers/stateless.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2942169225820013"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.mse(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednak samo zdefiniowanie funkcji straty nie wystarczy. Dobry model uczenia maszynowego musi mieć możliwie jak najniższy <b>błąd generalizacji</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://cdn-images-1.medium.com/max/1600/1*1woqrqfRwmS1xXYHKPMUDw.png)](https://buzzrobot.com/bias-and-variance-11d8e1fee627)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety sieci neuronowe mają tendencję do przeuczania się i w przypadku ich używania konieczne jest wykorzystanie odpowiedniej metody <b>regularyzacji</b>. Dzięki temu możliwe będzie zaproponowanie modelu, który będzie umiał efektywnie aproksymować dane inne niż trenujące.\n",
    "\n",
    "Do najczęściej wykorzystywanych metod regularyzacji należą:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>nakładanie kar na parametry</b>:\n",
    "\n",
    "Jeden z najczęściej wykorzystywanych sposobów regularyzacji. Polega on na nałożeniu unormowanej kary na parametry funkcji straty: \n",
    "     \n",
    "$\\tilde{J}(\\theta) = J(\\theta) + \\alpha\\Omega(\\theta)$\n",
    "\n",
    "Najczęściej spotykamy się z postaciami:\n",
    "- $\\Omega(\\theta) = ||\\theta||_1 = \\sum_i{|\\theta_i|}$     (<i>LASSO</i>,<i>regularyzacja $L_1$</i>)\n",
    "- $\\Omega(\\theta) = ||\\theta||_2^2 = \\sum_i{\\theta_i^2}$ (<i>regularyzacja Tichonowa</i>, <i>regresja grzbietowa</i>,<i>regularyzacja $L_2$</i>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich implementacja wyglądałaby [następująco](https://fluxml.ai/Flux.jl/stable/models/regularisation/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L₂ (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L₁(θ) = sum(abs, θ) \n",
    "L₂(θ) = sum(abs2, θ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(x,y,W) = loss(model(x),y) + L₁(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.397232938947592"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(x,y,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Bagging (bootstrap aggregating)</b>:\n",
    "\n",
    "Polega on na losowaniu ze zwracaniem $k$ próbek z wejściowego zbioru danych i szacowaniu na nich $k$  modeli, a następnie uśrednianiu ich rezultatów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dropout</b>:\n",
    "\n",
    "Polega na tworzeniu nowych modeli poprzez usuwanie neuronów z warstw ukrytych z prawdopodobieństwem $p$ w każdej iteracji uczenia. Niech wektor $\\mu = [1,1,0,1,1,1,\\dots,0,1]$ oznacza neurony wykorzystane do uczenia modelu w danej iteracji $i$. W takim wypadku procedura uczenia sprowadza się do minimalizacji wartości wyrażenia $E_\\mu[J(\\theta,\\mu)]$ dla każdej kolejnej iteracji. Dzięki temu otrzymujemy nieobciążony estymator gradientu bez konieczności generowania i uczenia $k$ modeli tak jak w przypadku baggingu.\n",
    "\n",
    "Dropout implementuje się we Fluxie jako [warstwę modelu](https://fluxml.ai/Flux.jl/stable/models/layers/#Normalisation-and-Regularisation-1): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(784 => 32, relu),               \u001b[90m# 25_120 parameters\u001b[39m\n",
       "  Dropout(0.1),\n",
       "  Dense(32 => 10),                      \u001b[90m# 330 parameters\u001b[39m\n",
       "  BatchNorm(64, relu),                  \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m        # Total: 6 trainable arrays, \u001b[39m25_578 parameters,\n",
       "\u001b[90m          # plus 2 non-trainable, 128 parameters, summarysize \u001b[39m100.922 KiB."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Dense(28^2, 32, relu),\n",
    "    Dropout(0.1),\n",
    "Dense(32, 10),\n",
    "BatchNorm(64, relu),\n",
    "softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalizacja sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Goodfellow I., Bengio Y., Courville A. (2016), Deep Learning, rozdział 8](http://www.deeplearningbook.org/contents/optimization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobór odpowiedniego algorytmu optymalizacyjnego jest jednym z najważniejszych kroków w trakcie przygotowywania sieci neuronowej. Specyfika procesu ich uczenia powoduje, że proces optymalizacji jest podatny na wiele potencjalnych problemów, między innymi:\n",
    "- złe uwarunkowanie macierzy.\n",
    "- występowanie lokalnych minimów, punktów siodłowych, etc.\n",
    "- zjawiska zanikającego i eksplodującego gradientu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z tego powodu istnieje wiele różnych algorytmów, które próbują przeciwdziałać wymienionym powyżej problemom. To który z nich powinien być zastosowany zależy tak naprawdę od specyfiki rozpatrywanego przypadku. Do najpopularnieszych należą:\n",
    "- SGD [(Robbins & Munro 1951)](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177729586)\n",
    "- SGD z pędem (momentum) [(Polyak, 1964)](http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=zvmmf&paperid=7713&option_lang=eng)\n",
    "- SGD z pędem Nesterova ([Nesterov, 1983](http://www.cis.pku.edu.cn/faculty/vision/zlin/1983-A%20Method%20of%20Solving%20a%20Convex%20Programming%20Problem%20with%20Convergence%20Rate%20O%28k%5E%28-2%29%29_Nesterov.pdf), [2005](https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf))\n",
    "- AdaGrad (Adaptive Gradient Algorithm) [(Duchi et. al. 2011)](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n",
    "- RMSProp [(Tieleman and Hinton 2012)](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
    "- ADAM (Adaptive Moment Estimation) [(Kingma & Ba, 2015)](https://arxiv.org/abs/1412.6980)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux umożliwia [wyznaczanie gradientu dowolnej funkcji](https://fluxml.ai/Flux.jl/stable/models/basics/) i przekazanie go do modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = 3x^2 + 2x + 1\n",
    "\n",
    "# df/dx = 6x + 2\n",
    "df(x) = gradient(f, x)[1]\n",
    "\n",
    "df(2) # 14.0 \n",
    "\n",
    "# d²f/dx² = 6\n",
    "d²f(x) = gradient(df, x)[1]\n",
    "\n",
    "d²f(2) # 6.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dotyczy to także dowolnych funkcji (nie tylko tych wyrażonych za pomocą metamatycznej formuły): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pow (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pow(x, n)\n",
    "    r = 1\n",
    "    for i = 1:n\n",
    "        r *= x\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(x -> pow(x, 3), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pow2 (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow2(x, n) = n <= 0 ? 1 : x*pow2(x, n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(x -> pow2(x, 3), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzieje się tak dzięki odpowiednio skonstruowanemu mechanizmowi różniczkowania, który efektywnie wykorzystuje charakterystykę języka.  Biblioteka [<tt>Zygote.jl</tt>](https://fluxml.ai/Zygote.jl/latest/) służy do automatycznego różniczkowania w Julii. Wprowadzenie do sposobu jej działania dostępne jest [tutaj](https://github.com/MikeInnes/diff-zoo) i [tutaj](https://arxiv.org/pdf/1810.07951.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatyczne różniczkowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kluczowym elementem poprawnie działającej biblioteki do uczenia maszynowego jest odpowiedni algorytm wyznaczający gradient funkcji. Jak wiemy z poprzednich zajęć naiwne wyznaczanie gradientu za pomocą definicji pochodnej:\n",
    "$$\\frac{df}{dx} = \\lim_{h \\to 0}\\frac{f(x_0 +h) - f(x_0)}{h}$$\n",
    "nie jest efektywne numerycznie. W jaki sposób możemy wyznaczać wartości pochodnych?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okazuje się, że każda, nawet najbardziej skomplikowana funkcja, którą liczymy jest niczym innym niż złożeniem podstawowych operacji arytmetycznych i kilku bazowych funkcji (sin,cos,log,etc.).  Znając podstawowe reguły wyliczania tych pochodnych możemy w efektywny sposób wyznaczyć wartość pochodnej korzystając z reguły łańcuchowej:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy_1}{dx}*\\frac{dy_2}{dy_1}*\\dots*\\frac{dy_{n-1}}{dy_{n-2}}*\\frac{dy}{dy_{n-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Różniczkowanie można wykonać na dwa sposoby:\n",
    "\n",
    "- <b>do przodu</b> zaczynamy ze znaną wartością $\\frac{dy_0}{dx} = \\frac{dx}{dx} = 1$. Następnie wyznaczamy wartość dla kolejnej instrukcji  $\\frac{dy_1}{dx} = \\frac{d_1}{dx} = 1$ i następnie:$\\frac{dy_{i+1}}{dy_i}$, aż otrzymamy pełny łańcuch.\n",
    "\n",
    "- <b>do tyłu</b> zaczynamy ze znaną wartością  $\\frac{dy}{dy_n} = \\frac{dy}{dy} = 1$. Następnie wyznaczamy wartości: $\\frac{dy}{dy_n}$, $\\frac{dy}{dy_{n-1}}$, ... $\\frac{dy}{dy_1}$, $\\frac{dy}{dx}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zygote.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De facto całe działanie biblioteki <tt>Zygote</tt> opiera się na dwóch kluczowych elementach: makrze <tt>@adjoint</tt> i funkcji <tt>pullback</tt>. \n",
    "\n",
    "<tt>pullback</tt> zwraca dwa wyniki, wartość oryginalnej funkcji $y = f(x)$ i wyrażenie $\\mathcal{B}(\\overline{y}) =  \\overline{y}  \\frac{dy}{dx}$, gdzie $\\overline{y} = \\frac{dl}{dy}$ jest parametrem, który musimy zdefiniować dla dowolnej funkcji $l$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, back = Zygote.pullback(sin, π);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W szczególności funkcja <tt>gradient</tt> zakłada, że  $l = y = f(x)$ i $\\overline{y} = \\frac{dy}{dl} = 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(sin,π) == back(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makro <tt>@adjoint</tt> pozwala nam w dowolny sposób modyfikować działanie mechanizmu wyznaczającego pochodne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote: @adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minus (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus(a,b) = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, -1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(minus,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minus2 (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus2(a,b) = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@adjoint minus2(a,b) = minus2(a,b), c̄ -> (nothing, -b^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nothing, -9.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(minus2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Flux ponadto posiada zdefiniowane [podstawowe algorytmy optymalizacyjne](https://fluxml.ai/Flux.jl/stable/training/optimisers/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.0001, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = ADAM(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Flux jest zdolny do kontrolowania całej procedury uczenia, nie musimy robić tego samodzielnie. Służy do tego funkcja <tt>train!</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: objective not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: objective not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[40]:1"
     ]
    }
   ],
   "source": [
    "Flux.train!(objective, data, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto jednak zaznaczyć, że pozwala ona na uczenie jedynie przez pojedynczą epokę. Aby móc kontynuować proces uczenia dalej musimy w odpowiedni sposób przystować dane z których korzystamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Vector{Float64}, Float64}}}(Base.Iterators.Repeated{Tuple{Vector{Float64}, Float64}}(([0.8250802168597535, 0.2666683690989766, 0.9702167605697445, 0.5370764734539006, 0.8064993544554011], 0.0)), 200)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Base.Iterators: repeated\n",
    "dataset = repeated((x, y), 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo skorzystać z makra <tt>@epochs</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 2\n"
     ]
    }
   ],
   "source": [
    "Flux.@epochs 2 println(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozwala ona też na definiowanie wywołań, które pozwolą nam kontrolować przebieg uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#19 (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb = () -> @show(loss(tX, tY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle, params\n",
    "using Base.Iterators: repeated\n",
    "using MLDatasets: MNIST, convert2image\n",
    "using Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od podstaw, wczytajmy i opracujmy zbiór danych na którym będziemy pracowali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset MNIST:\n",
       "  metadata  =>    Dict{String, Any} with 3 entries\n",
       "  split     =>    :train\n",
       "  features  =>    28×28×60000 Array{Float32, 3}\n",
       "  targets   =>    60000-element Vector{Int64}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = MNIST(:train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obejrzyjmy przykładowy obraz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{Float32},2} with eltype Gray{Float32}:\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱  \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert2image(MNIST,train_set.features)[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×60000 Matrix{Float32}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify MNIST digits with a simple multi-layer-perceptron\n",
    "\n",
    "# Stack images into one large batch\n",
    "X = reshape(float.(train_set.features),size(train_set.features,1) * size(train_set.features,2),size(train_set.features,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×60000 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n",
       " ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  1  ⋅  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  1  ⋅  1     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  1  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  1\n",
       " ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(train_set.targets, 0:9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(784 => 32, relu),               \u001b[90m# 25_120 parameters\u001b[39m\n",
       "  Dense(32 => 10),                      \u001b[90m# 330 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m25_450 parameters, 99.664 KiB."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako funkcję straty wykorzystamy binarną entropię krzyżową (<b> binary cross-entropy </b>, <b>log-loss</b>). Jej wzór to:\n",
    "\n",
    "$$ H_p(q) = - \\sum_{i=1}^N {y_i log(p(y_i)) + (1 - y_i) log(p(1 -y_i))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1227"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM()\n",
    "\n",
    "accuracy(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I zacznijmy proces uczenia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 2.2497776f0\n",
      "loss(X, Y) = 0.59707785f0\n",
      "loss(X, Y) = 0.3788935f0\n"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymane wyniki możemy zapisywać korzystając z biblioteki [<tt>BSON</tt>](https://github.com/JuliaIO/BSON.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = params(m)\n",
    "\n",
    "BSON.@save \"MNIST.bson\" model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i oczywiście wczytywać:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) \n",
    "\n",
    "model_params = params(m)\n",
    "\n",
    "BSON.@load \"MNIST.bson\" model_params\n",
    "\n",
    "Flux.loadparams!(m, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lub biblioteki [JLD2](https://github.com/JuliaIO/JLD2.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "\n",
    "jldsave(\"MNIST.jld2\"; model_params = params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) \n",
    "\n",
    "model_params = JLD2.load(\"MNIST.jld2\", \"model_params\")\n",
    "\n",
    "Flux.loadparams!(m, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie powinniśmy przyjrzeć się wynikom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set accuracy\n",
    "train_set = MNIST(:test)\n",
    "\n",
    "#reshape data\n",
    "tX = reshape(float.(train_set.features),size(train_set.features,1) * size(train_set.features,2) ,size(train_set.features,3))\n",
    "\n",
    "# One-hot-encode the labels\n",
    "tY = onehotbatch(train_set.targets, 0:9) \n",
    "\n",
    "accuracy(tX, tY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strojenie hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieć neuronowa potrafi zoptymalizować jedynie wagi $\\theta$ funkcji liniowych wykorzystanych do budowy modelu. Pozostałe parametry (funkcje aktywacji, metoda regularyzacji, stopa uczenia, etc.) muszą być przyjęte z góry. Dobrać je można na kilka różnych sposobów:\n",
    "- wzorując się na literaturze\n",
    "- zgadując parametry\n",
    "- tworząc model [zdolny do nauczenia się optymalnej metody uczenia](https://arxiv.org/abs/2004.05439)\n",
    "- przeszukując odpowiednio przestrzeń hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowa praca domowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Dokonaj strojenia hiperparametrów sieci omawianej na wykładzie. Sprobuj znaleźć taką, która zapewnia wyższą trafność predykcji <b>(5 punktów)</b>.\n",
    "2. W trakcie zajęć mówiliśmy o liczbach dualnych, czyli liczbach postaci $z = a + \\epsilon b$, gdzie $a,b \\in \\mathbb{R}$ a  $\\epsilon^2 = 0$. Dla dowolnego wielomanu  postaci $f(x) = a_0 + a_1x + a_2x^2 + \\dots + a_nx^n$ wartość takiego wielomianu dla liczby dualnej $z$ jest równa: $f(z) = f(a) + bf'(a)\\epsilon$. Pokaż, że tak jest naprawdę <b>(5 punktów)</b>. "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
